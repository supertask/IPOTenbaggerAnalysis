name: Sync EDINET IPO reports to MKC

on:
  schedule:
    # 毎月1日 09:00 JST（GitHubはUTC基準なので 00:00 UTC）
    - cron: '0 0 1 * *'
  push:
    tags:
      - 'center-*'        # 例: center-2025-08-31
  workflow_dispatch:

concurrency:
  group: sync-edinet-to-mkc
  cancel-in-progress: false

jobs:
  sync:
    runs-on: ubuntu-latest
    permissions:
      contents: read   # IPOTenbaggerAnalysis の読み取りのみ。書き込みはPATで実施
    steps:
      - name: Free up disk space
        run: |
          echo "=== Before cleanup ==="
          df -h
          
          # Remove unnecessary software to free up space
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo rm -rf /usr/local/share/boost
          sudo rm -rf /usr/local/graalvm/
          sudo rm -rf /usr/local/.ghcup/
          sudo rm -rf /usr/local/share/powershell
          sudo rm -rf /usr/local/share/chromium
          sudo rm -rf /usr/local/lib/node_modules
          
          # Clean apt cache
          sudo apt-get clean
          
          echo "=== After cleanup ==="
          df -h
      - name: Checkout IPOTenbaggerAnalysis (sparse)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          # 対象ディレクトリのみ取得して高速化
          sparse-checkout: |
            data/output/edinet_db/ipo_reports
          sparse-checkout-cone: true

      - name: Ensure secret exists
        run: |
          if [ -z "${{ secrets.MILLIONARE_KNOWLEDGE_CENTER_TOKEN }}" ]; then
            echo "::error::Secret MILLIONARE_KNOWLEDGE_CENTER_TOKEN is not set in IPOTenbaggerAnalysis (Settings > Secrets and variables > Actions)."
            exit 1
          fi

      - name: Checkout MillionareKnowledgeCenter
        uses: actions/checkout@v4
        with:
          repository: supertask/MillionareKnowledgeCenter
          ref: main                           # 宛先のデフォルトブランチに合わせて必要なら変更
          token: ${{ secrets.MILLIONARE_KNOWLEDGE_CENTER_TOKEN }}
          path: mkc
          fetch-depth: 0

      - name: Sync ipo_reports -> knowledge/edinet_db
        shell: bash
        run: |
          set -euo pipefail
          SRC_BASE="data/output/edinet_db/ipo_reports"
          DEST_BASE="mkc/knowledge/edinet_db"

          if [ ! -d "${SRC_BASE}" ]; then
            echo "Source base '${SRC_BASE}' not found. Nothing to sync."
            exit 0
          fi

          shopt -s nullglob
          # 直下の「フォルダ群」を列挙（ファイルは無視）
          dirs=("${SRC_BASE}"/*/)
          if [ ${#dirs[@]} -eq 0 ]; then
            echo "No folders under ${SRC_BASE}."
            exit 0
          fi

          echo "Total directories to sync: ${#dirs[@]}"
          echo "=== Disk space before sync ==="
          df -h

          # Process directories in smaller batches to manage disk usage
          # Start with a smaller batch size to be more conservative with disk space
          batch_size=20
          total_success=0
          total_failed=0
          
          # Disable immediate exit on error for the sync loop to handle errors gracefully
          set +e
          
          for ((i=0; i<${#dirs[@]}; i+=batch_size)); do
            batch_end=$((i + batch_size))
            if [ $batch_end -gt ${#dirs[@]} ]; then
              batch_end=${#dirs[@]}
            fi
            
            echo "=== Processing batch $((i/batch_size + 1)): directories $((i+1)) to $batch_end ==="
            
            sync_success=0
            sync_failed=0
            
            for ((j=i; j<batch_end; j++)); do
              src_dir="${dirs[j]}"
              cat_name="$(basename "${src_dir%/}")"
              dest_dir="${DEST_BASE}/${cat_name}"
              mkdir -p "${dest_dir}"

              echo "Syncing ${src_dir} -> ${dest_dir} ($(($j+1))/${#dirs[@]})"
              echo "  Source contents: $(ls -la "${src_dir}" 2>/dev/null | wc -l) items"
              
              # 最適化されたrsyncオプション：圧縮、進捗表示、効率的な転送
              echo "  About to execute rsync command..."
              rsync_exit_code=0
              rsync -avz --compress-level=6 --partial --inplace \
                --delete --delete-excluded \
                --exclude='.git/' \
                --exclude='.DS_Store' \
                --exclude='*.tmp' \
                --exclude='*.temp' \
                --timeout=300 \
                "${src_dir}/" "${dest_dir}/" || rsync_exit_code=$?
              
              echo "  rsync completed with exit code: ${rsync_exit_code}"
              
              if [ "${rsync_exit_code}" -eq 0 ]; then
                echo "✓ Successfully synced ${src_dir}"
                echo "  Destination contents: $(ls -la "${dest_dir}" 2>/dev/null | wc -l) items"
                ((sync_success++))
              else
                echo "✗ Failed to sync ${src_dir} (error code: ${rsync_exit_code})"
                ((sync_failed++))
                
                # If disk space is the issue, try to free up space and continue
                available_space=$(df . | tail -1 | awk '{print $4}')
                if [ "$available_space" -lt 500000 ]; then  # Less than 500MB
                  echo "Critical: Very low disk space. Attempting emergency cleanup..."
                  sudo apt-get clean
                  docker system prune -af 2>/dev/null || true
                  find /tmp -type f -name "*.tmp" -delete 2>/dev/null || true
                  find /var/tmp -type f -name "*.tmp" -delete 2>/dev/null || true
                  
                  # Check if we have enough space to continue
                  available_space=$(df . | tail -1 | awk '{print $4}')
                  if [ "$available_space" -lt 500000 ]; then
                    echo "Error: Still insufficient disk space after cleanup. Cannot continue."
                    exit 1
                  fi
                fi
              fi
              
              echo "  Completed processing directory $(($j+1))/${#dirs[@]}: ${cat_name}"
            done
            
            echo "Batch $((i/batch_size + 1)) summary: ${sync_success} successful, ${sync_failed} failed"
            
            # Update total counters
            ((total_success += sync_success))
            ((total_failed += sync_failed))
            
            # Check disk usage after each batch and clean up if needed
            echo "=== Disk usage after batch $((i/batch_size + 1)) ==="
            df -h
            
            # Clean up temporary files
            find . -name "*.tmp" -type f -delete 2>/dev/null || true
            find . -name "*.temp" -type f -delete 2>/dev/null || true
            
            # If disk usage is getting high, trigger garbage collection
            available_space=$(df . | tail -1 | awk '{print $4}')
            if [ "$available_space" -lt 1000000 ]; then  # Less than 1GB available
              echo "Warning: Low disk space ($available_space KB available). Running cleanup..."
              sudo apt-get clean
              docker system prune -f 2>/dev/null || true
            fi
          done
          
          # Re-enable immediate exit on error after sync loop
          set -e
          
          # Final sync statistics
          echo "=== SYNC COMPLETE ==="
          echo "Total directories processed: ${#dirs[@]}"
          echo "Successfully synced: ${total_success}"
          echo "Failed to sync: ${total_failed}"
          
          if [ "$total_failed" -gt 0 ]; then
            echo "⚠️  Warning: Some directories failed to sync. Check logs above for details."
            if [ "$total_failed" -gt "$((${#dirs[@]} / 2))" ]; then
              echo "❌ Error: More than half of the directories failed. Exiting with error."
              exit 1
            fi
          else
            echo "✅ All directories synced successfully!"
          fi

      - name: Final cleanup before commit
        shell: bash
        run: |
          echo "=== Final disk status ==="
          df -h
          
          # Final cleanup of temporary files in the entire workspace
          find . -name "*.tmp" -type f -delete 2>/dev/null || true
          find . -name "*.temp" -type f -delete 2>/dev/null || true
          find . -name ".DS_Store" -type f -delete 2>/dev/null || true
          
          echo "=== After final cleanup ==="
          df -h

      - name: Commit & Push to MillionareKnowledgeCenter
        shell: bash
        run: |
          set -euo pipefail
          cd mkc
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          # 念のため .DS_Store を一掃（同期範囲外に紛れた場合の保険）
          find knowledge/edinet_db -name '.DS_Store' -type f -delete || true
          find knowledge/edinet_db -name '*.tmp' -type f -delete || true
          find knowledge/edinet_db -name '*.temp' -type f -delete || true

          git add -A
          if git diff --staged --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          if [[ "${GITHUB_REF:-}" == refs/tags/* ]]; then
            TAG_NAME="${GITHUB_REF#refs/tags/}"
            git commit -m "chore(sync): EDINET IPO reports from IPOTenbaggerAnalysis (tag ${TAG_NAME})"
          else
            git commit -m "chore(sync): EDINET IPO reports from IPOTenbaggerAnalysis ($(date -u +'%Y-%m-%dT%H:%M:%SZ'))"
          fi

          git push origin HEAD
